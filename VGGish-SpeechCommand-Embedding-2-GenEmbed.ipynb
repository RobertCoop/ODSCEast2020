{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# VGGish - Speech Commands - Embedding Generation\n\n**Pipeline Step 2: Feature Extraction with VGGish**\n\nThis notebook takes the spectrograms generated in the previous step and passes each one through the pre-trained VGGish network to produce a 128-dimensional embedding vector. These embeddings serve as compact, semantically meaningful feature representations of each audio clip.\n\n**Why embeddings?** Rather than training a classifier directly on the raw 96x64 spectrograms (6,144 values), we can use VGGish's pre-trained knowledge to compress each spectrogram into a 128-dimensional vector. This is the \"feature extraction\" approach to transfer learning -- using a pre-trained network as a fixed feature extractor.\n\n**Pipeline context:**\n1. Generate spectrograms (previous notebook)\n2. **Generate embeddings** (this notebook) -- Pass spectrograms through VGGish\n3. Train classifier (next notebook) -- Use embeddings as input features"
  },
  {
   "cell_type": "markdown",
   "source": "## Setup\n\nImport TensorFlow and the VGGish library. This notebook was run on an AWS instance with 16 GPUs (p3.16xlarge), though the embedding generation loop uses a single GPU session.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/ubuntu/odsc/vggish/lib/models/research/audioset/vggish\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vggish_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.96, 0.96)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vggish_params.EXAMPLE_HOP_SECONDS, vggish_params.EXAMPLE_WINDOW_SECONDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/odsc/vggish/env/lib/python3.6/site-packages/tensorflow_core/python/compat/v2_compat.py:68: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "Num GPUs Available:  16\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import six\n",
    "import soundfile\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/device:GPU:0',\n",
       " '/device:GPU:1',\n",
       " '/device:GPU:2',\n",
       " '/device:GPU:3',\n",
       " '/device:GPU:4',\n",
       " '/device:GPU:5',\n",
       " '/device:GPU:6',\n",
       " '/device:GPU:7',\n",
       " '/device:GPU:8',\n",
       " '/device:GPU:9',\n",
       " '/device:GPU:10',\n",
       " '/device:GPU:11',\n",
       " '/device:GPU:12',\n",
       " '/device:GPU:13',\n",
       " '/device:GPU:14',\n",
       " '/device:GPU:15']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "def get_available_gpus():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos if x.device_type == 'GPU']\n",
    "\n",
    "get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import vggish_input\n",
    "import vggish_postprocess\n",
    "import vggish_slim\n",
    "\n",
    "pca_params = '/home/ubuntu/odsc/vggish/lib/vggish_pca_params.npz'\n",
    "ckpt = '/home/ubuntu/odsc/vggish/lib/vggish_model.ckpt'"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## Loading Pre-Generated Spectrograms\n\nLoad the spectrogram data saved in the previous notebook. The binary file contains the raw float64 values of all 105,835 spectrograms, which we reshape into `(105835, 96, 64)` -- one 96x64 spectrogram per audio file.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ubuntu/odsc/vggish'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(105835, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('wavfile_df.csv', index_col=0)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('wavfile_spec.dat', 'rb') as f:\n",
    "    audio_data = np.fromfile(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_array = audio_data.reshape((-1, 96, 64))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## Defining the VGGish Inference Pipeline\n\nDefine the VGGish model in inference mode (`training=False`) and load the pre-trained checkpoint. The model takes spectrograms as input (`features_tensor`) and produces 128-dim embeddings as output (`embedding_tensor`). No weights are updated during this step -- VGGish acts as a fixed feature extractor.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "## Generating Embeddings in Batches\n\nProcessing all 105,835 spectrograms at once would exceed GPU memory, so we split them into 20 batches (~5,290 spectrograms each). Each batch is fed through VGGish, and the resulting embeddings are stored in a pre-allocated output array.\n\nThe output is a matrix of shape `(105835, 128)` -- one 128-dimensional embedding vector per audio file.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(105835, 96, 64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(105835, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "### Examining the Raw Embedding\n\nEach embedding is a 128-dimensional vector of non-negative floating-point values (due to the ReLU activation). Many values are zero, while non-zero values capture different learned audio features. The sparse, non-negative structure is typical of deep network activations.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "### Post-Processing (Optional)\n\nThe VGGish authors provide a post-processing step that applies PCA, whitening, and quantization to convert the 128-dim float32 embeddings into 128-dim uint8 vectors. This was designed for compatibility with the YouTube-8M pipeline. Below, we demonstrate this step but use the **raw float32 embeddings** for our downstream classification tasks.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_and_init_vggish():\n",
    "    # Define the model in inference mode, load the checkpoint, and\n",
    "    # locate input and output tensors.\n",
    "    vggish_slim.define_vggish_slim(training=False)\n",
    "    vggish_slim.load_vggish_slim_checkpoint(sess, ckpt)\n",
    "    features_tensor = sess.graph.get_tensor_by_name(\n",
    "        vggish_params.INPUT_TENSOR_NAME)\n",
    "    embedding_tensor = sess.graph.get_tensor_by_name(\n",
    "        vggish_params.OUTPUT_TENSOR_NAME)\n",
    "\n",
    "    return features_tensor, embedding_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## Saving Embeddings\n\nSave the raw embeddings both as a binary file (`wavfile_embed.dat`) and as additional columns in the metadata DataFrame (`wavfile_embed.csv`). The CSV file contains the original metadata (file_name, label, valid) plus 128 embedding columns (e0 through e127), making it convenient for downstream analysis and modeling.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "batches = np.array_split(np.arange(audio_array.shape[0]), 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/ubuntu/odsc/vggish/lib/vggish_model.ckpt\n",
      "Processed 5291\n",
      "Processed 10583\n",
      "Processed 15875\n",
      "Processed 21167\n",
      "Processed 26459\n",
      "Processed 31751\n",
      "Processed 37043\n",
      "Processed 42335\n",
      "Processed 47627\n",
      "Processed 52919\n",
      "Processed 58211\n",
      "Processed 63503\n",
      "Processed 68795\n",
      "Processed 74087\n",
      "Processed 79379\n",
      "Processed 84670\n",
      "Processed 89961\n",
      "Processed 95252\n",
      "Processed 100543\n",
      "Processed 105834\n"
     ]
    }
   ],
   "source": [
    "with tf.Graph().as_default(), tf.Session() as sess:\n",
    "    features_tensor, embedding_tensor = define_and_init_vggish()\n",
    "    \n",
    "    for b in batches:\n",
    "        [embedding_output[b]] = sess.run([embedding_tensor],\n",
    "                                 feed_dict={features_tensor: audio_array[b,:,:]})\n",
    "        print('Processed {}'.format(b.max()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(105835, 128)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.57563651, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.80524492, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.09647748,\n",
       "       0.        , 0.2215701 , 0.36531198, 0.        , 0.        ,\n",
       "       0.10503449, 0.        , 0.43128461, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.09738244, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.71650451, 0.45736679,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.07548475, 0.        , 0.04537981, 0.        , 0.        ,\n",
       "       0.28914386, 0.        , 0.42669204, 0.        , 0.72561944,\n",
       "       0.00455567, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 1.11860538, 0.        , 0.19068947, 0.01635753,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.0788549 ,\n",
       "       0.        , 0.        , 0.15197024, 0.        , 0.02502114,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.61964613, 0.46234041, 0.64971781, 0.        ,\n",
       "       0.35118836, 0.60920829, 0.        , 0.        , 0.02227074,\n",
       "       0.        , 0.12507463, 0.        , 0.        , 0.54457295,\n",
       "       0.        , 0.        , 0.16407022, 0.76613104, 0.        ,\n",
       "       0.11072141, 0.        , 0.        , 0.        , 0.74897075,\n",
       "       0.        , 0.        , 0.        , 0.34730688, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.00565439, 0.11364996, 0.        ,\n",
       "       0.        , 0.        , 0.02634976, 0.        , 0.        ,\n",
       "       0.        , 0.09891669, 0.39739999, 0.        , 0.        ,\n",
       "       0.        , 0.08000683, 0.        ])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_output[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "pproc = vggish_postprocess.Postprocessor(pca_params)\n",
    "postprocessed = pproc.postprocess(embedding_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([158,  14, 154, 100, 205,  72, 121,  65, 132, 249,  96,  86, 101,\n",
       "       154,  70, 161, 100, 100, 163, 121,  16, 255, 134,  67,  66, 131,\n",
       "       168, 210,  64, 186, 228, 102,  32,  75,   0, 219,  46,   0, 148,\n",
       "       152,   0, 197,  96,  92, 187, 111, 255, 193,  93, 225, 160,  82,\n",
       "        91,  76, 115, 106, 255,  42, 149, 137, 117,  93,  45, 220,  83,\n",
       "        90, 144,   4, 129, 190, 136, 140, 172,  64, 108, 132,   0, 255,\n",
       "        15,  48,  16,  92, 161, 101,  82, 158, 127, 145, 255,  32, 255,\n",
       "       129,  52,   6, 149, 255, 218,  98, 253, 218,  47, 135, 255, 173,\n",
       "         0,   0,  50,  45, 255,  78, 140,  85,  84,  41, 255,   0,  76,\n",
       "       247,   0, 167, 123, 116,  13,   0, 168,   0, 178, 255], dtype=uint8)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "postprocessed[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('wavfile_embed.dat', 'wb') as f:\n",
    "    embedding_output.tofile(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(embedding_output.shape[1]):\n",
    "    df[f'e{i}'] = embedding_output[:, i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>label</th>\n",
       "      <th>valid</th>\n",
       "      <th>e0</th>\n",
       "      <th>e1</th>\n",
       "      <th>e2</th>\n",
       "      <th>e3</th>\n",
       "      <th>e4</th>\n",
       "      <th>e5</th>\n",
       "      <th>e6</th>\n",
       "      <th>...</th>\n",
       "      <th>e118</th>\n",
       "      <th>e119</th>\n",
       "      <th>e120</th>\n",
       "      <th>e121</th>\n",
       "      <th>e122</th>\n",
       "      <th>e123</th>\n",
       "      <th>e124</th>\n",
       "      <th>e125</th>\n",
       "      <th>e126</th>\n",
       "      <th>e127</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/ubuntu/audio/speech_commands/zero/8a90cf...</td>\n",
       "      <td>zero</td>\n",
       "      <td>True</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.575637</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.098917</td>\n",
       "      <td>0.3974</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.080007</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/ubuntu/audio/speech_commands/zero/173ae7...</td>\n",
       "      <td>zero</td>\n",
       "      <td>True</td>\n",
       "      <td>0.813162</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.280367</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006822</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.072240</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.272675</td>\n",
       "      <td>0.463936</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018412</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/ubuntu/audio/speech_commands/zero/eb76bc...</td>\n",
       "      <td>zero</td>\n",
       "      <td>True</td>\n",
       "      <td>0.701961</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.114244</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.084316</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.571525</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.838637</td>\n",
       "      <td>0.160843</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/ubuntu/audio/speech_commands/zero/978240...</td>\n",
       "      <td>zero</td>\n",
       "      <td>True</td>\n",
       "      <td>0.751647</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.163232</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.623571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.692807</td>\n",
       "      <td>0.924771</td>\n",
       "      <td>0.304728</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/ubuntu/audio/speech_commands/zero/246328...</td>\n",
       "      <td>zero</td>\n",
       "      <td>True</td>\n",
       "      <td>1.115380</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.111188</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.141433</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.760137</td>\n",
       "      <td>0.021478</td>\n",
       "      <td>0.095431</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 131 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           file_name label  valid        e0  \\\n",
       "0  /home/ubuntu/audio/speech_commands/zero/8a90cf...  zero   True  0.000000   \n",
       "1  /home/ubuntu/audio/speech_commands/zero/173ae7...  zero   True  0.813162   \n",
       "2  /home/ubuntu/audio/speech_commands/zero/eb76bc...  zero   True  0.701961   \n",
       "3  /home/ubuntu/audio/speech_commands/zero/978240...  zero   True  0.751647   \n",
       "4  /home/ubuntu/audio/speech_commands/zero/246328...  zero   True  1.115380   \n",
       "\n",
       "    e1        e2   e3        e4   e5   e6  ...  e118      e119  e120  \\\n",
       "0  0.0  0.575637  0.0  0.000000  0.0  0.0  ...   0.0  0.000000   0.0   \n",
       "1  0.0  0.280367  0.0  0.006822  0.0  0.0  ...   0.0  0.072240   0.0   \n",
       "2  0.0  0.114244  0.0  0.000000  0.0  0.0  ...   0.0  0.084316   0.0   \n",
       "3  0.0  0.163232  0.0  0.000000  0.0  0.0  ...   0.0  0.623571   0.0   \n",
       "4  0.0  0.111188  0.0  0.000000  0.0  0.0  ...   0.0  0.141433   0.0   \n",
       "\n",
       "       e121    e122      e123      e124      e125      e126  e127  \n",
       "0  0.098917  0.3974  0.000000  0.000000  0.000000  0.080007   0.0  \n",
       "1  0.000000  0.0000  1.272675  0.463936  0.000000  0.018412   0.0  \n",
       "2  0.000000  0.0000  0.571525  0.000000  0.838637  0.160843   0.0  \n",
       "3  0.000000  0.0000  0.692807  0.924771  0.304728  0.000000   0.0  \n",
       "4  0.000000  0.0000  0.760137  0.021478  0.095431  0.000000   0.0  \n",
       "\n",
       "[5 rows x 131 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('wavfile_embed.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}